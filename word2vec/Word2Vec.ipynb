{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSIi052WQN7L"
      },
      "source": [
        "### Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMj276Meor9K"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS_m4gAqQoOL"
      },
      "source": [
        "import gensim\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format('/content/drive/MyDrive/datasets/model.bin', binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO_PZn7z1M63"
      },
      "source": [
        "model.vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej1COe3X1iNq"
      },
      "source": [
        "mom = model.get_vector('мама_NOUN')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuAts-mR1y4P"
      },
      "source": [
        "wash = model.get_vector('мыть_VERB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCH6Rvb818Em"
      },
      "source": [
        "model.cosine_similarities(mom, wash.reshape((-1, 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TOCaChh3TQP"
      },
      "source": [
        "queen = model.get_vector('королева_NOUN')\n",
        "king = model.get_vector('король_NOUN')\n",
        "\n",
        "man = model.get_vector('мужчина_NOUN')\n",
        "woman = model.get_vector('женщина_NOUN')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L37fIUigBLp5"
      },
      "source": [
        "model.get_vector('кек_NOUN')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOWCTP6I2xv-",
        "outputId": "b019a6dd-0f61-4633-b337-45a914997f2e"
      },
      "source": [
        "model.similar_by_vector(king - man + woman)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('король_NOUN', 0.8779481649398804),\n",
              " ('герцог_NOUN', 0.7090673446655273),\n",
              " ('король_PROPN', 0.6953890323638916),\n",
              " ('королева_NOUN', 0.67110276222229),\n",
              " ('королева_ADV', 0.645533561706543),\n",
              " ('карл_PROPN', 0.6311907172203064),\n",
              " ('максимилиан_PROPN', 0.6286245584487915),\n",
              " ('дофин_NOUN', 0.6282011270523071),\n",
              " ('принц_NOUN', 0.6229782104492188),\n",
              " ('королевство_NOUN', 0.6215177774429321)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2-5rOAXQYhR"
      },
      "source": [
        "### CBOW https://github.com/FraLotito/pytorch-continuous-bag-of-words/blob/master/cbow.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nHyISzXZauu"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def make_context_vector(context, word_to_ix):\n",
        "    idxs = [word_to_ix[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
        "EMDEDDING_DIM = 100\n",
        "\n",
        "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
        "Computational processes are abstract beings that inhabit computers.\n",
        "As they evolve, processes manipulate other abstract things called data.\n",
        "The evolution of a process is directed by a pattern of rules\n",
        "called a program. People create programs to direct processes. In effect,\n",
        "we conjure the spirits of the computer with our spells.\"\"\".split()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc7RskoCZkK2"
      },
      "source": [
        "# By deriving a set from `raw_text`, we deduplicate the array\n",
        "vocab = set(raw_text)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "word_to_ix = {word:ix for ix, word in enumerate(vocab)}\n",
        "ix_to_word = {ix:word for ix, word in enumerate(vocab)}\n",
        "\n",
        "data = []\n",
        "for i in range(2, len(raw_text) - 2):\n",
        "    context = [raw_text[i - 2], raw_text[i - 1],\n",
        "               raw_text[i + 1], raw_text[i + 2]]\n",
        "    target = raw_text[i]\n",
        "    data.append((context, target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6iav-R9ZmcF"
      },
      "source": [
        "class CBOW(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(CBOW, self).__init__()\n",
        "\n",
        "        #out: 1 x emdedding_dim\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(embedding_dim, 128)\n",
        "        self.activation_function1 = nn.ReLU()\n",
        "        \n",
        "        #out: 1 x vocab_size\n",
        "        self.linear2 = nn.Linear(128, vocab_size)\n",
        "        self.activation_function2 = nn.LogSoftmax(dim = -1)\n",
        "        \n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = sum(self.embeddings(inputs)).view(1,-1)\n",
        "        out = self.linear1(embeds)\n",
        "        out = self.activation_function1(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.activation_function2(out)\n",
        "        return out\n",
        "\n",
        "    def get_word_emdedding(self, word):\n",
        "        word = torch.tensor([word_to_ix[word]])\n",
        "        return self.embeddings(word).view(1,-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COdaLacwZoCS",
        "outputId": "4be2352c-bb94-411f-a94b-4b8df5a3aa2e"
      },
      "source": [
        "model = CBOW(vocab_size, EMDEDDING_DIM)\n",
        "\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "#TRAINING\n",
        "for epoch in range(50):\n",
        "    total_loss = 0\n",
        "\n",
        "    for context, target in data:\n",
        "        context_vector = make_context_vector(context, word_to_ix)  \n",
        "\n",
        "        log_probs = model(context_vector)\n",
        "\n",
        "        total_loss += loss_function(log_probs, torch.tensor([word_to_ix[target]]))\n",
        "\n",
        "    #optimize at the end of each epoch\n",
        "    optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "#TESTING\n",
        "context = ['People','create','to', 'direct']\n",
        "context_vector = make_context_vector(context, word_to_ix)\n",
        "a = model(context_vector)\n",
        "\n",
        "#Print result\n",
        "print(f'Raw text: {\" \".join(raw_text)}\\n')\n",
        "print(f'Context: {context}\\n')\n",
        "print(f'Prediction: {ix_to_word[torch.argmax(a[0]).item()]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Raw text: We are about to study the idea of a computational process. Computational processes are abstract beings that inhabit computers. As they evolve, processes manipulate other abstract things called data. The evolution of a process is directed by a pattern of rules called a program. People create programs to direct processes. In effect, we conjure the spirits of the computer with our spells.\n",
            "\n",
            "Context: ['People', 'create', 'to', 'direct']\n",
            "\n",
            "Prediction: programs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35xA_bA4QS8c"
      },
      "source": [
        "## Skip-Gram https://github.com/blackredscarf/pytorch-SkipGram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOcANXgUQWwL"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class SkipGramNeg(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim):\n",
        "        super(SkipGramNeg, self).__init__()\n",
        "        self.input_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.output_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.log_sigmoid = nn.LogSigmoid()\n",
        "\n",
        "        initrange = (2.0 / (vocab_size + emb_dim)) ** 0.5  # Xavier init\n",
        "        self.input_emb.weight.data.uniform_(-initrange, initrange)\n",
        "        self.output_emb.weight.data.uniform_(-0, 0)\n",
        "\n",
        "\n",
        "    def forward(self, target_input, context, neg):\n",
        "        \"\"\"\n",
        "        :param target_input: [batch_size]\n",
        "        :param context: [batch_size]\n",
        "        :param neg: [batch_size, neg_size]\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        # u,v: [batch_size, emb_dim]\n",
        "        v = self.input_emb(target_input)\n",
        "        u = self.output_emb(context)\n",
        "        # positive_val: [batch_size]\n",
        "        positive_val = self.log_sigmoid(torch.sum(u * v, dim=1)).squeeze()\n",
        "\n",
        "        # u_hat: [batch_size, neg_size, emb_dim]\n",
        "        u_hat = self.output_emb(neg)\n",
        "        # [batch_size, neg_size, emb_dim] x [batch_size, emb_dim, 1] = [batch_size, neg_size, 1]\n",
        "        # neg_vals: [batch_size, neg_size]\n",
        "        neg_vals = torch.bmm(u_hat, v.unsqueeze(2)).squeeze(2)\n",
        "        # neg_val: [batch_size]\n",
        "        neg_val = self.log_sigmoid(-torch.sum(neg_vals, dim=1)).squeeze()\n",
        "\n",
        "        loss = positive_val + neg_val\n",
        "        return -loss.mean()\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        return self.input_emb(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b72axs-4luWp"
      },
      "source": [
        "## FastText https://towardsdatascience.com/deep-learning-for-nlp-with-pytorch-and-torchtext-4f92d69052f"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5GvaoXblkan"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "\n",
        "from torchtext.data import Field \n",
        "from torchtext.data import Dataset, Example\n",
        "from torchtext.data import BucketIterator\n",
        "from torchtext.vocab import FastText\n",
        "from torchtext.vocab import CharNGram\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLeeZ0eflkao"
      },
      "source": [
        "embedding = FastText('simple')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwjH3XaYlkao"
      },
      "source": [
        "# embedding_charngram = CharNGram()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv1xaRtqlkap",
        "outputId": "94eb75fe-37e4-419d-df72-5fe7e69b2c21"
      },
      "source": [
        "df = pd.DataFrame([\n",
        "    ['my name is Jack', 'Y'],\n",
        "    ['Hi I am Jack', 'Y'],\n",
        "    ['Hello There!', 'Y'],\n",
        "    ['Hi I am cooking', 'N'],\n",
        "    ['Hello are you there?', 'N'],\n",
        "    ['There is a bird there', 'N'],\n",
        "], columns=['text', 'label'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>my name is Jack</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi I am Jack</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hello There!</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hi I am cooking</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hello are you there?</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>There is a bird there</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    text label\n",
              "0        my name is Jack     Y\n",
              "1           Hi I am Jack     Y\n",
              "2           Hello There!     Y\n",
              "3        Hi I am cooking     N\n",
              "4   Hello are you there?     N\n",
              "5  There is a bird there     N"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wchJmfzllkaq"
      },
      "source": [
        "text_field = Field(\n",
        "    sequential=True,\n",
        "    tokenize='basic_english', \n",
        "    fix_length=5,\n",
        "    lower=True\n",
        ")\n",
        "\n",
        "label_field = Field(sequential=False, use_vocab=False)\n",
        "\n",
        "# sadly have to apply preprocess manually\n",
        "preprocessed_text = df['text'].apply(\n",
        "    lambda x: text_field.preprocess(x)\n",
        ")\n",
        "\n",
        "# load fastext simple embedding with 300d\n",
        "text_field.build_vocab(\n",
        "    preprocessed_text, \n",
        "    vectors='fasttext.simple.300d'\n",
        ")\n",
        "\n",
        "# get the vocab instance\n",
        "vocab = text_field.vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j6l5wcJlkaq",
        "outputId": "cdbdcc29-9ae2-41d6-b89f-b8eb2162007d"
      },
      "source": [
        "# known token, in my case print 12\n",
        "print(vocab['are'])\n",
        "# unknown token, will print 0\n",
        "print(vocab['crazy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGWprQqHlkar",
        "outputId": "168bb6b3-73ca-4c31-aeaa-025efef9d3bf"
      },
      "source": [
        "for i, r in df.iterrows():\n",
        "    print(list(r.values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['my name is Jack', 'Y']\n",
            "['Hi I am Jack', 'Y']\n",
            "['Hello There!', 'Y']\n",
            "['Hi I am cooking', 'N']\n",
            "['Hello are you there?', 'N']\n",
            "['There is a bird there', 'N']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtzO-d_Wlkar"
      },
      "source": [
        "# we still have to manually handle conversion from categorical to int\n",
        "ltoi = {l: i for i, l in enumerate(df['label'].unique())}\n",
        "df['label'] = df['label'].apply(lambda y: ltoi[y])\n",
        "\n",
        "class DataFrameDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, fields: list):\n",
        "        super(DataFrameDataset, self).__init__(\n",
        "            [\n",
        "                Example.fromlist(list(r), fields) \n",
        "                for i, r in df.iterrows()\n",
        "            ], \n",
        "            fields\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh_TsDealkar"
      },
      "source": [
        "train_dataset, test_dataset = DataFrameDataset(\n",
        "    df=df, \n",
        "    fields=(\n",
        "        ('text', text_field),\n",
        "        ('label', label_field)\n",
        "    )\n",
        ").split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNAFilaWlkas"
      },
      "source": [
        "train_iter, test_iter = BucketIterator.splits(\n",
        "    datasets=(train_dataset, test_dataset), \n",
        "    batch_sizes=(2, 2),\n",
        "    sort=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-X6aAWnlkas"
      },
      "source": [
        "class ModelParam(object):\n",
        "    def __init__(self, param_dict: dict = dict()):\n",
        "        self.input_size = param_dict.get('input_size', 0)\n",
        "        self.vocab_size = param_dict.get('vocab_size')\n",
        "        self.embedding_dim = param_dict.get('embedding_dim', 300)\n",
        "        self.target_dim = param_dict.get('target_dim', 2)\n",
        "        \n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self, model_param: ModelParam):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(\n",
        "            model_param.vocab_size, \n",
        "            model_param.embedding_dim\n",
        "        )\n",
        "        self.lin = nn.Linear(\n",
        "            model_param.input_size * model_param.embedding_dim, \n",
        "            model_param.target_dim\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        features = self.embedding(x).view(x.size()[0], -1)\n",
        "        features = F.relu(features)\n",
        "        features = self.lin(features)\n",
        "        return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzJw0Ggxlkas"
      },
      "source": [
        "class MyModelWithPretrainedEmbedding(nn.Module):\n",
        "    def __init__(self, model_param: ModelParam, embedding):\n",
        "        super().__init__()\n",
        "        self.embedding = embedding\n",
        "        self.lin = nn.Linear(\n",
        "            model_param.input_size * model_param.embedding_dim, \n",
        "            model_param.target_dim\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        features = self.embedding[x].reshape(x.size()[0], -1)\n",
        "        features = F.relu(features)\n",
        "        features = self.lin(features)\n",
        "        return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7O-hrFDlkat",
        "outputId": "0d9fba75-8b82-46d9-af6a-c98b22077b86"
      },
      "source": [
        "model_param = ModelParam(\n",
        "    param_dict=dict(\n",
        "        vocab_size=len(text_field.vocab),\n",
        "        input_size=5\n",
        "    )\n",
        ")\n",
        "model = MyModel(model_param)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "epochs = 5\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_losses = list()\n",
        "    for batch in train_iter:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        prediction = model(batch.text.T)\n",
        "        loss = loss_function(prediction, batch.label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_losses.append(loss.item())\n",
        "    print('train loss on epoch {} : {:.3f}'.format(epoch, np.mean(epoch_losses)))\n",
        "    \n",
        "    test_losses = list()\n",
        "    for batch in test_iter:\n",
        "        with torch.no_grad():\n",
        "            optimizer.zero_grad()\n",
        "            prediction = model(batch.text.T)\n",
        "            loss = loss_function(prediction, batch.label)\n",
        "            \n",
        "            test_losses.append(loss.item())\n",
        "    \n",
        "    print('test loss on epoch {}: {:.3f}'.format(epoch, np.mean(test_losses)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train loss on epoch 0 : 0.439\n",
            "test loss on epoch 0: 5.784\n",
            "train loss on epoch 1 : 0.002\n",
            "test loss on epoch 1: 8.804\n",
            "train loss on epoch 2 : 0.000\n",
            "test loss on epoch 2: 11.002\n",
            "train loss on epoch 3 : 0.000\n",
            "test loss on epoch 3: 12.678\n",
            "train loss on epoch 4 : 0.000\n",
            "test loss on epoch 4: 13.999\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}