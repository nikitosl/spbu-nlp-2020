{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WznpuM32at0"
   },
   "outputs": [],
   "source": [
    "# Загрузка датасета из репозитория гит\n",
    "!git clone https://github.com/nikitosl/spbu-nlp-2020.git\n",
    "import sys\n",
    "sys.path.append('./spbu-nlp-2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WAw_7OtU2bxa"
   },
   "outputs": [],
   "source": [
    "# Импорты\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from string import punctuation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6La0xy8c2gmm"
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# # Для лемматизации\n",
    "\n",
    "# !pip install stanza\n",
    "# !pip install spacy_stanza\n",
    "# !pip install pymorphy2==0.8\n",
    "# stanza.download('ru') \n",
    "# import stanza\n",
    "# from spacy_stanza import StanzaLanguage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "0lsyk6mb0UDo"
   },
   "source": [
    "### Чтение файла Война и мир"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "bPgmGVkc0UDp"
   },
   "outputs": [],
   "source": [
    "with open('./spbu-nlp-2020/text_preprocessing/war_and_peace.txt', 'r', encoding='cp1251') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "CjV0bpCs0UDp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "RPT8fXcD0UDs"
   },
   "source": [
    "### Токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "4__NCuI60UDs"
   },
   "source": [
    "#### Токенизация с помощью регулярных выражений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "yduJ3ZmV0UDs"
   },
   "outputs": [],
   "source": [
    "re_tokenized_text = re.findall(r'\\w+', text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "HV-MD2Yt0UDt"
   },
   "outputs": [],
   "source": [
    "re_tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "YlVBnRdL0UDt"
   },
   "source": [
    "#### Частоты слов после токенизации RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "zl_MrYE90UDu"
   },
   "outputs": [],
   "source": [
    "cntr = Counter(re_tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "MYbIjTGR0UDu"
   },
   "outputs": [],
   "source": [
    "cntr_df = pd.DataFrame(cntr.items(), columns=['Word', 'Number']) \\\n",
    "    .sort_values(by='Number', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Lv7JXt1W0UDu"
   },
   "outputs": [],
   "source": [
    "cntr_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "-tkyR1fm0UDu"
   },
   "source": [
    "#### Токенизация с помощью NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "jjS-3EXW0UDu"
   },
   "outputs": [],
   "source": [
    "nltk_tokenized_text = nltk.word_tokenize(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "KtfJdics0UDu"
   },
   "outputs": [],
   "source": [
    "nltk_tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "MCaOZq8s0UDv"
   },
   "source": [
    "#### Частоты слов после токенизации NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "D4lbeRaM0UDv"
   },
   "outputs": [],
   "source": [
    "cntr = Counter(nltk_tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "UUxnM84W0UDv"
   },
   "outputs": [],
   "source": [
    "cntr_df = pd.DataFrame(cntr.items(), columns=['Word', 'Number']) \\\n",
    "    .sort_values(by='Number', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "OYKXPQhZ0UDw"
   },
   "outputs": [],
   "source": [
    "cntr_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "JxFyzvUE0UDw"
   },
   "source": [
    "### Удалениие стоп-слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "lvX2Jrdc0UDw"
   },
   "source": [
    "#### Удалениие стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Vba5A1Jz0UDw"
   },
   "outputs": [],
   "source": [
    "russian_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "G4MtWkZ-3VkB"
   },
   "outputs": [],
   "source": [
    "punctuation = punctuation + '–»«`’'\n",
    "clear_tokenized_text = [token for token in nltk_tokenized_text \\\n",
    "                          if token not in russian_stopwords and token not in punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "VWnAyLfr34S7"
   },
   "outputs": [],
   "source": [
    "clear_tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "kVS40y8l0UDx"
   },
   "source": [
    "#### Частоты слов после удаления стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "pOcP83_Z0UDx"
   },
   "outputs": [],
   "source": [
    "cntr = Counter(clear_tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "sWcWmuV10UDx"
   },
   "outputs": [],
   "source": [
    "cntr_df = pd.DataFrame(cntr.items(), columns=['Word', 'Number']) \\\n",
    "    .sort_values(by='Number', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "d-mhn2U60UDx"
   },
   "outputs": [],
   "source": [
    "cntr_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "djFJBgeY0UDx"
   },
   "source": [
    "### Стемминг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "BGIVj4xx0UDx"
   },
   "source": [
    "#### Стемминг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "5358Ixuv0UDx"
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"russian\")\n",
    "\n",
    "stemm_text = [stemmer.stem(token) for token in clear_tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "in768CXf4_Ha"
   },
   "outputs": [],
   "source": [
    "stemm_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "VaWyqV6R5Lso"
   },
   "source": [
    "#### Частоты слов после стемминга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "g1Ewk9035Lso"
   },
   "outputs": [],
   "source": [
    "cntr = Counter(stemm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "YIFVRJs25Lso"
   },
   "outputs": [],
   "source": [
    "cntr_df = pd.DataFrame(cntr.items(), columns=['Word', 'Number']) \\\n",
    "    .sort_values(by='Number', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "sARPNMM65Lso"
   },
   "outputs": [],
   "source": [
    "cntr_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "t-ohukQY0UDx"
   },
   "source": [
    "### Лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "HJ4J91760UDy"
   },
   "source": [
    "#### Лемматизация (может занять много времени)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "xEEfzUza5YYf"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "snlp = stanza.Pipeline(lang=\"ru\")\n",
    "nlp = StanzaLanguage(snlp)\n",
    "\n",
    "# Разбиваем на два куска, так как максимальная длина входа 1000000 символов\n",
    "gap = len(nltk_tokenized_text) // 2\n",
    "subtext1 = ' '.join(nltk_tokenized_text[:gap])\n",
    "subtext2 = ' '.join(nltk_tokenized_text[gap:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "5jPfh5oik1q-"
   },
   "outputs": [],
   "source": [
    "doc1 = nlp(subtext1)\n",
    "doc2 = nlp(subtext2)\n",
    "\n",
    "lemm_text = [token.lemma_ for token in doc1] + [token.lemma_ for token in doc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "7ilkv3a9q5AY"
   },
   "outputs": [],
   "source": [
    "lemm_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "bq1An0ke5cL_"
   },
   "source": [
    "#### Частоты слов после лемматизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "B271Hte95cL_"
   },
   "outputs": [],
   "source": [
    "cntr = Counter(lemm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "d2MFj4n-5cL_"
   },
   "outputs": [],
   "source": [
    "cntr_df = pd.DataFrame(cntr.items(), columns=['Word', 'Number']) \\\n",
    "    .sort_values(by='Number', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "8a0i1LMP5cL_"
   },
   "outputs": [],
   "source": [
    "cntr_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "A7H7AaWQ0UDy"
   },
   "source": [
    "### Мешок слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "4W6entc35Z6S"
   },
   "outputs": [],
   "source": [
    "parts_number = 5\n",
    "part_size = len(stemm_text) // parts_number\n",
    "text_parts = [stemm_text[i:i+part_size] for i in range(0, len(stemm_text), part_size)][:parts_number]\n",
    "unique_words = Counter(stemm_text).keys()\n",
    "print(f'Всего уникальных слов в тексте: {len(unique_words)}')\n",
    "word2num = dict([(word, num) for num, word in enumerate(unique_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "rm-0XbfuGqLO"
   },
   "outputs": [],
   "source": [
    "def get_bag_of_words(text):\n",
    "    res = np.zeros(len(word2num))\n",
    "    for word in text:\n",
    "        res[word2num[word]] += 1\n",
    "    return res\n",
    "bags_of_words = [get_bag_of_words(part) for part in text_parts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "7R9m9NGEIX1C"
   },
   "outputs": [],
   "source": [
    "bow_df = pd.DataFrame([*bags_of_words], columns=word2num.keys(), index=range(1, parts_number + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "-USHLHBBJA_j"
   },
   "outputs": [],
   "source": [
    "bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "5xN5_g4M0UDy"
   },
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "9yPdmo930UDy"
   },
   "outputs": [],
   "source": [
    "tf = bow_df / part_size # Важность токена в документе\n",
    "idf = np.log(parts_number / (bow_df != 0).sum(axis=0)) # Важность токена по всем документам\n",
    "tf_idf = tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "UbxylJ6NMPuV"
   },
   "outputs": [],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "QNQYIQY_N13z"
   },
   "outputs": [],
   "source": [
    "important_features = tf_idf.loc[:, (tf_idf.sum(axis=0) > 0.002)]\n",
    "(important_features >= important_features.max(axis=0) / 2).astype(int)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "0lsyk6mb0UDo",
    "RPT8fXcD0UDs",
    "4__NCuI60UDs",
    "YlVBnRdL0UDt",
    "-tkyR1fm0UDu",
    "JxFyzvUE0UDw",
    "lvX2Jrdc0UDw",
    "djFJBgeY0UDx",
    "t-ohukQY0UDx",
    "A7H7AaWQ0UDy",
    "5xN5_g4M0UDy"
   ],
   "name": "Копия блокнота \"war_and_peace.ipynb\"",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
